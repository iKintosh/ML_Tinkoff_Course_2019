{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from scipy import stats\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(data, label, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_method(clf, params, data, labels, test, y_test):\n",
    "    CV = GridSearchCV(clf, param_grid=params, n_jobs=-1, cv=3)\n",
    "    CV.fit(data, labels)\n",
    "    print(f'Best score: {CV.best_score_}')\n",
    "    print(f'Test score: {CV.score(test, y_test)}')\n",
    "    print(f'Best params: {CV.best_params_}')\n",
    "    return CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8696\n",
      "Test score: 0.8691666666666666\n",
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iLeks\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs'],\n",
    "        'C': [0.1, 1, 2]\n",
    "    }\n",
    "\n",
    "log_reg_CV = fit_method(LogisticRegression(multi_class='multinomial'), params, train[:5000], y_train[:5000], test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9406\n",
      "Test score: 0.9515476190476191\n",
      "Best params: {'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'kernel': ['poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_CV = fit_method(SVC(), params, train[:5000], y_train[:5000], test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9354\n",
      "Test score: 0.9415476190476191\n",
      "Best params: {'max_depth': None, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [1,5,10,50,100,200,500],\n",
    "    'max_depth': [2, 5, None]\n",
    "}\n",
    "\n",
    "rfc_CV = fit_method(RandomForestClassifier(), params, train[:5000], y_train[:5000], test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.574\n",
      "Test score: 0.7022619047619048\n",
      "Best params: {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [1,5,10,50,100,200],\n",
    "}\n",
    "\n",
    "ab_CV = fit_method(AdaBoostClassifier(), params, train[:5000], y_train[:5000], test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9244\n",
      "Test score: 0.934404761904762\n",
      "Best params: {'leaf_size': 5, 'n_neighbors': 1, 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': [1,5,10,50,100,200],\n",
    "    'leaf_size': [5, 30, 100],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_CV = fit_method(KNeighborsClassifier(), params, train[:5000], y_train[:5000], test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упростим датасет заменив все значения >0 единицами. Запустим модели с лучшими параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_simple = train.copy()\n",
    "train_simple[train_simple>0] = 1\n",
    "\n",
    "test_simple = test.copy()\n",
    "test_simple[test_simple>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iLeks\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8941666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_simple = LogisticRegression(**log_reg_CV.best_params_)\n",
    "log_reg_simple.fit(train_simple[:5000], y_train[:5000])\n",
    "log_reg_simple.score(test_simple, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465476190476191"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_simple = RandomForestClassifier(**rfc_CV.best_params_)\n",
    "rfc_simple.fit(train_simple[:5000], y_train[:5000])\n",
    "rfc_simple.score(test_simple, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488095238095238"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_simple = SVC(**svm_CV.best_params_)\n",
    "svm_simple.fit(train_simple[:5000], y_train[:5000])\n",
    "svm_simple.score(test_simple, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(train)\n",
    "train_scaled = sc.transform(train)\n",
    "test_scaled = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(train_scaled)\n",
    "train_pca = pca.transform(train_scaled)\n",
    "test_pca = pca.transform(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Variance')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_per = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "ind = np.arange(len(var_per)) \n",
    "plt.bar(ind,var_per)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = np.sum(pca.explained_variance_ratio_.cumsum()<=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 222)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_comp).fit(train_scaled)\n",
    "train_pca = pca.transform(train_scaled)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "print(train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9366\n",
      "Test score: 0.9497619047619048\n",
      "Best params: {'C': 1000, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'kernel': ['poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "    'C': [1000, 100, 10, 1]\n",
    "}\n",
    "svm_CV = fit_method(SVC(), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8964\n",
      "Test score: 0.9069047619047619\n",
      "Best params: {'leaf_size': 5, 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': [1, 5, 10],\n",
    "    'leaf_size': [5, 30]\n",
    "}\n",
    "\n",
    "knn_CV = fit_method(KNeighborsClassifier(), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8874\n",
      "Test score: 0.8996428571428572\n",
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iLeks\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs'],\n",
    "        'C': [0.1, 1, 2]\n",
    "    }\n",
    "\n",
    "log_reg_CV = fit_method(LogisticRegression(multi_class='multinomial'), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(train_scaled)\n",
    "train_pca = pca.transform(train_scaled)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "n_comp = np.sum(pca.explained_variance_ratio_.cumsum()<=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 112)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_comp).fit(train_scaled)\n",
    "train_pca = pca.transform(train_scaled)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "print(train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9374\n",
      "Test score: 0.9471428571428572\n",
      "Best params: {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'kernel': ['poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "    'C': [1000, 100, 10, 1]\n",
    "}\n",
    "svm_CV = fit_method(SVC(), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9118\n",
      "Test score: 0.9226190476190477\n",
      "Best params: {'leaf_size': 5, 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': [1, 5, 10],\n",
    "    'leaf_size': [1, 5, 30]\n",
    "}\n",
    "\n",
    "knn_CV = fit_method(KNeighborsClassifier(), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8894\n",
      "Test score: 0.8909523809523809\n",
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iLeks\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs'],\n",
    "        'C': [0.1, 1, 2]\n",
    "    }\n",
    "\n",
    "log_reg_CV = fit_method(LogisticRegression(multi_class='multinomial'), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще уменьшим размерность пространства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 50)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=50).fit(train_scaled)\n",
    "train_pca = pca.transform(train_scaled)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "print(train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.942\n",
      "Test score: 0.9467857142857142\n",
      "Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'kernel': ['poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "    'C': [1000, 100, 10, 1]\n",
    "}\n",
    "svm_CV = fit_method(SVC(), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9112\n",
      "Test score: 0.9232142857142858\n",
      "Best params: {'leaf_size': 5, 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': [1, 5, 10],\n",
    "    'leaf_size': [5, 30]\n",
    "}\n",
    "\n",
    "knn_CV = fit_method(KNeighborsClassifier(n_jobs=-1), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8894\n",
      "Test score: 0.8926190476190476\n",
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs'],\n",
    "        'C': [0.1, 1, 2]\n",
    "    }\n",
    "\n",
    "log_reg_CV = fit_method(LogisticRegression(multi_class='multinomial', n_jobs=-1), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9076\n",
      "Test score: 0.9145238095238095\n",
      "Best params: {'max_depth': None, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [1,5,10,50,100,200,500],\n",
    "    'max_depth': [2, 5, None]\n",
    "}\n",
    "\n",
    "rfc_CV = fit_method(RandomForestClassifier(n_jobs=-1), params, train_pca[:5000], y_train[:5000], test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732142857142857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(**svm_CV.best_params_, probability=True)\n",
    "svm.fit(train_pca[:], y_train[:])\n",
    "svm.score(test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9530952380952381"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(**knn_CV.best_params_)\n",
    "knn.fit(train_pca[:], y_train[:])\n",
    "knn.score(test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iLeks\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\iLeks\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8886904761904761"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(**log_reg_CV.best_params_)\n",
    "log_reg.fit(train_pca[:], y_train[:])\n",
    "log_reg.score(test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9463095238095238"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(**rfc_CV.best_params_)\n",
    "rfc.fit(train_pca[:], y_train[:])\n",
    "rfc.score(test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter = VotingClassifier(estimators=[('svm', svm), ('knn', knn), ('rfc', rfc)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svm',\n",
       "                              SVC(C=10, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='scale', kernel='rbf',\n",
       "                                  max_iter=-1, probability=True,\n",
       "                                  random_state=None, shrinking=True, tol=0.001,\n",
       "                                  verbose=False)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                   leaf_size=5,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n...\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=500,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter.fit(train_pca[:], y_train[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705952380952381"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter.score(test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('test.csv')\n",
    "\n",
    "label = data['label']\n",
    "data.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(data)\n",
    "data_scaled = sc.transform(data)\n",
    "val_scaled = sc.transform(val)\n",
    "\n",
    "pca = PCA(n_components=50).fit(data_scaled)\n",
    "\n",
    "data_pca = pca.transform(data_scaled)\n",
    "val_pca = pca.transform(val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(**svm_CV.best_params_, probability=True)\n",
    "svm.fit(data_pca, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svm.predict(val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = np.arange(1, 28001)\n",
    "sub['Label'] = prediction\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
